{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting house prices using k-nearest neighbors regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will implement k-nearest neighbors regression. You will:\n",
    "\n",
    "Find the k-nearest neighbors of a given query input\n",
    "Predict the output for the query input using the k-nearest neighbors\n",
    "Choose the best value of k using a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':float, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv('kc_house_data_small.csv', dtype = dtype_dict)\n",
    "train = pd.read_csv('kc_house_data_small_train.csv', dtype = dtype_dict)\n",
    "test = pd.read_csv('kc_house_data_small_test.csv', dtype = dtype_dict)\n",
    "validate = pd.read_csv('kc_house_data_validation 2.csv', dtype = dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. To efficiently compute pairwise distances among data points, we will convert the SFrame (or dataframe) into a 2D Numpy array. First import the numpy library and then copy and paste get_numpy_data() (or equivalent). The function takes a dataset, a list of features (e.g. [‘sqft_living’, ‘bedrooms’]) to be used as inputs, and a name of the output (e.g. ‘price’). It returns a ‘features_matrix’ (2D array) consisting of a column of ones followed by columns containing the values of the input features in the data set in the same order as the input list. It also returns an ‘output_array’, which is an array of the values of the output in the dataset (e.g. ‘price’).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data, features, output):\n",
    "    data['constant'] = 1 # add a constant column to a dataframe\n",
    "    # prepend variable 'constant' to the features list\n",
    "    features = ['constant'] + features\n",
    "    # select the columns of dataframe given by the ‘features’ list into the SFrame ‘features_sframe’\n",
    "\n",
    "    # this will convert the features_sframe into a numpy matrix with GraphLab Create >= 1.7!!\n",
    "    features_matrix = data[features].as_matrix(columns=None)\n",
    "    # assign the column of data_sframe associated with the target to the variable ‘output_sarray’\n",
    "\n",
    "    # this will convert the SArray into a numpy array:\n",
    "    output_array = data[output].as_matrix(columns=None) \n",
    "    return(features_matrix, output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, copy and paste the normalize_features function (or equivalent) from Module 5 (Ridge Regression). Given a feature matrix, each column is divided (element-wise) by its 2-norm. The function returns two items: (i) a feature matrix with normalized columns and (ii) the norms of the original columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_features(features):\n",
    "    norms = np.sqrt(np.sum(features**2,axis=0))\n",
    "    normlized_features = features/norms\n",
    "    return (normlized_features, norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using get_numpy_data (or equivalent), extract numpy arrays of the training, test, and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = [m for m,n in dtype_dict.items() if train[m].dtypes != object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bathrooms',\n",
       " 'sqft_living15',\n",
       " 'sqft_above',\n",
       " 'grade',\n",
       " 'yr_built',\n",
       " 'price',\n",
       " 'bedrooms',\n",
       " 'long',\n",
       " 'sqft_lot15',\n",
       " 'sqft_living',\n",
       " 'floors',\n",
       " 'sqft_lot',\n",
       " 'waterfront',\n",
       " 'sqft_basement',\n",
       " 'yr_renovated',\n",
       " 'lat',\n",
       " 'condition',\n",
       " 'view']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features.remove('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_feature_matrix, training_output = get_numpy_data(train, features, 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing_feature_matrix, testing_output = get_numpy_data(test, features, 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validating_feature_matrix, validating_output = get_numpy_data(validate, features, 'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In computing distances, it is crucial to normalize features. Otherwise, for example, the ‘sqft_living’ feature (typically on the order of thousands) would exert a much larger influence on distance than the ‘bedrooms’ feature (typically on the order of ones). We divide each column of the training feature matrix by its 2-norm, so that the transformed column has unit norm.\n",
    "\n",
    "IMPORTANT: Make sure to store the norms of the features in the training set. The features in the test and validation sets must be divided by these same norms, so that the training, test, and validation sets are normalized consistently.\n",
    "\n",
    "e.g. in Python:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_train, norms = normalize_features(training_feature_matrix)\n",
    "features_test = testing_feature_matrix / norms\n",
    "features_valid = validating_feature_matrix / norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Compute a single distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, let's just explore computing the “distance” between two given houses. We will take our query house to be the first house of the test set and look at the distance between this house and the 10th house of the training set.\n",
    "\n",
    "To see the features associated with the query house, print the first row (index 0) of the test feature matrix. You should get an 18-dimensional vector whose components are between 0 and 1. Similarly, print the 10th row (index 9) of the training feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01345102  0.01807473  0.01375926  0.01362084  0.01564352  0.01350306\n",
      "  0.01551285 -0.01346922  0.0016225   0.01759212  0.017059    0.00160518\n",
      "  0.          0.02481682  0.          0.01345387  0.0116321   0.05102365]\n",
      "[ 0.01345102  0.00602491  0.01195898  0.0096309   0.01390535  0.01302544\n",
      "  0.01163464 -0.01346251  0.00156612  0.0083488   0.01279425  0.00050756\n",
      "  0.          0.          0.          0.01346821  0.01938684  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print features_test[0]\n",
    "print features_train[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz Question: What is the Euclidean distance between the query house and the 10th house of the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059723593713980776"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum((features_train[9] - features_test[0])**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, to do nearest neighbor regression, we need to compute the distance between our query house and all houses in the training set.\n",
    "\n",
    "To visualize this nearest-neighbor search, let's first compute the distance from our query house (features_test[0]) to the first 10 houses of the training set (features_train[0:10]) and then search for the nearest neighbor within this small set of houses. Through restricting ourselves to a small set of houses to begin with, we can visually scan the list of 10 distances to verify that our code for finding the nearest neighbor is working.\n",
    "\n",
    "Write a loop to compute the Euclidean distance from the query house to each of the first 10 houses in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz Question: Among the first 10 training houses, which house is the closest to the query house?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.060274709162955922, 1: 0.085468811476437465, 2: 0.061499464352793153, 3: 0.053402739792943632, 4: 0.058444840601704413, 5: 0.059879215098128345, 6: 0.0546314049677546, 7: 0.055431083236146074, 8: 0.052383627840220305, 9: 0.059723593713980776}\n"
     ]
    }
   ],
   "source": [
    "distance = {}\n",
    "for i in range(10):\n",
    "    distance[i] = np.sqrt(np.sum((features_train[i] - features_test[0])**2))\n",
    "print distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distance_2 = []\n",
    "for x,y in distance.items():\n",
    "    distance_2.append((y,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distance_2.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.052383627840220305, 8),\n",
       " (0.053402739792943632, 3),\n",
       " (0.0546314049677546, 6),\n",
       " (0.055431083236146074, 7),\n",
       " (0.058444840601704413, 4),\n",
       " (0.059723593713980776, 9),\n",
       " (0.059879215098128345, 5),\n",
       " (0.060274709162955922, 0),\n",
       " (0.061499464352793153, 2),\n",
       " (0.085468811476437465, 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is computationally inefficient to loop over computing distances to all houses in our training dataset. Fortunately, many of the numpy functions can be vectorized, applying the same operation over multiple values or vectors. We now walk through this process. (The material up to #13 is specific to numpy; if you are using other languages such as R or Matlab, consult relevant manuals on vectorization.)\n",
    "\n",
    "Consider the following loop that computes the element-wise difference between the features of the query house (features_test[0]) and the first 3 training houses (features_train[0:3]):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.00000000e+00  -1.20498190e-02  -5.14364795e-03  -5.50336860e-03\n",
      "  -3.47633726e-03  -1.63756198e-04  -3.87821276e-03   1.29876855e-05\n",
      "   6.69281453e-04  -1.05552733e-02  -8.52950206e-03   2.08673616e-04\n",
      "   0.00000000e+00  -2.48168183e-02   0.00000000e+00  -1.70254220e-05\n",
      "   0.00000000e+00  -5.10236549e-02]\n",
      "[  0.00000000e+00  -4.51868214e-03  -2.89330197e-03   1.30705004e-03\n",
      "  -3.47633726e-03  -1.91048898e-04  -3.87821276e-03   6.16364736e-06\n",
      "   1.47606982e-03  -2.26610387e-03   0.00000000e+00   7.19763456e-04\n",
      "   0.00000000e+00  -1.45830788e-02   6.65082271e-02   4.23090220e-05\n",
      "   0.00000000e+00  -5.10236549e-02]\n",
      "[  0.00000000e+00  -1.20498190e-02   3.72914476e-03  -8.32384500e-03\n",
      "  -5.21450589e-03  -3.13866046e-04  -7.75642553e-03   1.56292487e-05\n",
      "   1.64764925e-03  -1.30002801e-02  -8.52950206e-03   1.60518166e-03\n",
      "   0.00000000e+00  -2.48168183e-02   0.00000000e+00   4.70885840e-05\n",
      "   0.00000000e+00  -5.10236549e-02]\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(3):\n",
    "    print features_train[i]-features_test[0]\n",
    "    # should print 3 vectors of length 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.00000000e+00  -1.20498190e-02  -5.14364795e-03  -5.50336860e-03\n",
      "   -3.47633726e-03  -1.63756198e-04  -3.87821276e-03   1.29876855e-05\n",
      "    6.69281453e-04  -1.05552733e-02  -8.52950206e-03   2.08673616e-04\n",
      "    0.00000000e+00  -2.48168183e-02   0.00000000e+00  -1.70254220e-05\n",
      "    0.00000000e+00  -5.10236549e-02]\n",
      " [  0.00000000e+00  -4.51868214e-03  -2.89330197e-03   1.30705004e-03\n",
      "   -3.47633726e-03  -1.91048898e-04  -3.87821276e-03   6.16364736e-06\n",
      "    1.47606982e-03  -2.26610387e-03   0.00000000e+00   7.19763456e-04\n",
      "    0.00000000e+00  -1.45830788e-02   6.65082271e-02   4.23090220e-05\n",
      "    0.00000000e+00  -5.10236549e-02]\n",
      " [  0.00000000e+00  -1.20498190e-02   3.72914476e-03  -8.32384500e-03\n",
      "   -5.21450589e-03  -3.13866046e-04  -7.75642553e-03   1.56292487e-05\n",
      "    1.64764925e-03  -1.30002801e-02  -8.52950206e-03   1.60518166e-03\n",
      "    0.00000000e+00  -2.48168183e-02   0.00000000e+00   4.70885840e-05\n",
      "    0.00000000e+00  -5.10236549e-02]]\n"
     ]
    }
   ],
   "source": [
    "print features_train[0:3] - features_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output of this vectorized operation is identical to that of the loop above, which can be verified below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# verify that vectorization works\n",
    "results = features_train[0:3] - features_test[0]\n",
    "print results[0] - (features_train[0]-features_test[0])\n",
    "# should print all 0's if results[0] == (features_train[0]-features_test[0])\n",
    "print results[1] - (features_train[1]-features_test[0])\n",
    "# should print all 0's if results[1] == (features_train[1]-features_test[0])\n",
    "print results[2] - (features_train[2]-features_test[0])\n",
    "# should print all 0's if results[2] == (features_train[2]-features_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform 1-nearest neighbor regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the element-wise differences, it is not too hard to compute the Euclidean distances between our query house and all of the training houses. First, write a single-line expression to define a variable ‘diff’ such that ‘diff[i]’ gives the element-wise difference between the features of the query house and the i-th training house.\n",
    "\n",
    "To test your code, print diff[-1].sum(), which should be -0.0934339605842."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,  -1.20498190e-02,  -5.14364795e-03, ...,\n",
       "         -1.70254220e-05,   0.00000000e+00,  -5.10236549e-02],\n",
       "       [  0.00000000e+00,  -4.51868214e-03,  -2.89330197e-03, ...,\n",
       "          4.23090220e-05,   0.00000000e+00,  -5.10236549e-02],\n",
       "       [  0.00000000e+00,  -1.20498190e-02,   3.72914476e-03, ...,\n",
       "          4.70885840e-05,   0.00000000e+00,  -5.10236549e-02],\n",
       "       ..., \n",
       "       [  0.00000000e+00,  -3.01245476e-03,   8.35842791e-04, ...,\n",
       "         -9.19146535e-06,   0.00000000e+00,  -5.10236549e-02],\n",
       "       [  0.00000000e+00,  -3.01245476e-03,   2.44323277e-03, ...,\n",
       "         -1.63183862e-05,   0.00000000e+00,  -5.10236549e-02],\n",
       "       [  0.00000000e+00,  -3.01245476e-03,  -3.92203156e-03, ...,\n",
       "          3.61719513e-05,   0.00000000e+00,  -5.10236549e-02]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = features_train[:] - features_test[0]\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,  -1.20498190e-02,  -5.14364795e-03, ...,\n",
       "         -1.70254220e-05,   0.00000000e+00,  -5.10236549e-02],\n",
       "       [  0.00000000e+00,  -4.51868214e-03,  -2.89330197e-03, ...,\n",
       "          4.23090220e-05,   0.00000000e+00,  -5.10236549e-02],\n",
       "       [  0.00000000e+00,  -1.20498190e-02,   3.72914476e-03, ...,\n",
       "          4.70885840e-05,   0.00000000e+00,  -5.10236549e-02],\n",
       "       ..., \n",
       "       [  0.00000000e+00,  -3.01245476e-03,   8.35842791e-04, ...,\n",
       "         -9.19146535e-06,   0.00000000e+00,  -5.10236549e-02],\n",
       "       [  0.00000000e+00,  -3.01245476e-03,   2.44323277e-03, ...,\n",
       "         -1.63183862e-05,   0.00000000e+00,  -5.10236549e-02],\n",
       "       [  0.00000000e+00,  -3.01245476e-03,  -3.92203156e-03, ...,\n",
       "          3.61719513e-05,   0.00000000e+00,  -5.10236549e-02]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train - features_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.09343399874654644"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff[-1].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in computing the Euclidean distances is to take these feature-by-feature differences in ‘diff’, square each, and take the sum over feature indices. That is, compute the sum of squared feature differences for each training house (row in ‘diff’).\n",
    "\n",
    "By default, ‘np.sum’ sums up everything in the matrix and returns a single number. To instead sum only over a row or column, we need to specifiy the ‘axis’ parameter described in the np.sum documentation. In particular, ‘axis=1’ computes the sum across each row.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_row = np.sum(diff**2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5527,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_row.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5527, 18)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "computes this sum of squared feature differences for all training houses. Verify that the two expressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0033070590284564457"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(diff**2, axis=1)[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0033070590284564453"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(diff[15]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this result in mind, write a single-line expression to compute the Euclidean distances from the query to all the instances. Assign the result to variable distances.\n",
    "\n",
    "Hint: don't forget to take the square root of the sum of squares.\n",
    "\n",
    "Hint: distances[100] should contain 0.0237082324496."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023708232416678195"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(sum(diff[100]**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to write a function that computes the distances from a query house to all training houses. The function should take two parameters: (i) the matrix of training features and (ii) the single feature vector associated with the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_distances(features_query):\n",
    "    diff = features_train - features_test[features_query]\n",
    "    distances = np.sqrt(np.sum(diff**2, axis=1))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist = compute_distances(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01954476,  0.06861035,  0.02165079, ...,  0.02433478,\n",
       "        0.02622734,  0.02637942])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0028604955575117085"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz Question: What is the predicted value of the query house based on 1-nearest neighbor regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249000.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_output[382]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Perform k-nearest neighbor regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the functions above, implement a function that takes in\n",
    "\n",
    "the value of k;\n",
    "the feature matrix for the instances; and\n",
    "the feature of the query\n",
    "and returns the indices of the k closest training houses. For instance, with 2-nearest neighbor, a return value of [5, 10] would indicate that the 6th and 11th training houses are closest to the query house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_nearest_neighbors(k, feat_query):\n",
    "    distance = compute_distances(feat_query)\n",
    "#     print np.sort(distance)[:k]\n",
    "    return np.argsort(distance)[0:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz Question: Take the query house to be third house of the test set (features_test[2]). What are the indices of the 4 training houses closest to the query house?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 382, 1149, 4087, 3142])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_nearest_neighbors(4,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to find the k-nearest neighbors, write a function that predicts the value of a given query house. For simplicity, take the average of the prices of the k nearest neighbors in the training set. The function should have the following parameters:\n",
    "\n",
    "the value of k;\n",
    "the feature matrix for the instances;\n",
    "the output values (prices) of the instances; and\n",
    "the feature of the query, whose price we’re predicting.\n",
    "The function should return a predicted value of the query house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_output_of_query(k, features_train, output_train, features_query):\n",
    "    prediction = np.sum(output_train[k_nearest_neighbors(k,features_query)])/k\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz Question: Make predictions for the first 10 houses in the test set, using k=10. What is the index of the house in this query set that has the lowest predicted value? What is the predicted value of this house?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 881300.0\n",
      "1 431860.0\n",
      "2 460595.0\n",
      "3 430200.0\n",
      "4 766750.0\n",
      "5 667420.0\n",
      "6 350032.0\n",
      "7 512800.7\n",
      "8 484000.0\n",
      "9 457235.0\n"
     ]
    }
   ],
   "source": [
    "for m in range(10):\n",
    "    print m, predict_output_of_query(10, features_train, training_output, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the best value of k using a validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There remains a question of choosing the value of k to use in making predictions. Here, we use a validation set to choose this value. Write a loop that does the following:\n",
    "\n",
    "For k in [1, 2, … 15]:\n",
    "\n",
    "Make predictions for the VALIDATION data using the k-nearest neighbors from the TRAINING data.\n",
    "Compute the RSS on VALIDATION data\n",
    "Report which k produced the lowest RSS on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-6a82f89f0932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrss_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpredictions_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_output_of_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mrss_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_k\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mvalidating_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-ba395aec2987>\u001b[0m in \u001b[0;36mpredict_output_of_query\u001b[0;34m(k, features_train, output_train, features_query)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_output_of_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk_nearest_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-c2db805e9728>\u001b[0m in \u001b[0;36mk_nearest_neighbors\u001b[0;34m(k, feat_query)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mk_nearest_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#     print np.sort(distance)[:k]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-877557a808c3>\u001b[0m in \u001b[0;36mcompute_distances\u001b[0;34m(features_query)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_train\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfeatures_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures_query\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "rss_all = np.zeros(15)\n",
    "for k in range(1,16):\n",
    "    predictions_k = predict_output_of_query(k, features_train, training_output, features_valid)\n",
    "    rss_all[k-1] = np.sum((predictions_k-validating_output)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
