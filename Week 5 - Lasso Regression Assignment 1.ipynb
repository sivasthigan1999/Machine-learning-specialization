{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':float, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n",
    "sales = pd.read_csv('kc_house_data.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new features by performing following transformation on inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "sales['floors_square'] = sales['floors']*sales['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\n",
    "On the other hand, taking square root of sqft_living will decrease the separation between big house and small house. The owner may not be exactly twice as happy for getting a house that is twice as big.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the entire house dataset, learn regression weights using an L1 penalty of 5e2. Make sure to add \"normalize=True\" when creating the Lasso object. Refer to the following code snippet for the list of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=500.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=True, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model  # using scikit-learn\n",
    "\n",
    "all_features = ['bedrooms', 'bedrooms_square',\n",
    "            'bathrooms',\n",
    "            'sqft_living', 'sqft_living_sqrt',\n",
    "            'sqft_lot', 'sqft_lot_sqrt',\n",
    "            'floors', 'floors_square',\n",
    "            'waterfront', 'view', 'condition', 'grade',\n",
    "            'sqft_above',\n",
    "            'sqft_basement',\n",
    "            'yr_built', 'yr_renovated']\n",
    "\n",
    "model_all = linear_model.Lasso(alpha=5e2, normalize=True) # set parameters\n",
    "model_all.fit(sales[all_features], sales['price']) # learn weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz Question: Which features have been chosen by LASSO, i.e. which features were assigned nonzero weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bedrooms                0.000000\n",
       "bedrooms_square         0.000000\n",
       "bathrooms               0.000000\n",
       "sqft_living           134.439314\n",
       "sqft_living_sqrt        0.000000\n",
       "sqft_lot                0.000000\n",
       "sqft_lot_sqrt           0.000000\n",
       "floors                  0.000000\n",
       "floors_square           0.000000\n",
       "waterfront              0.000000\n",
       "view                24750.004586\n",
       "condition               0.000000\n",
       "grade               61749.103091\n",
       "sqft_above              0.000000\n",
       "sqft_basement           0.000000\n",
       "yr_built               -0.000000\n",
       "yr_renovated            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model_all.coef_,index=all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a good L1 penalty, we will explore multiple values using a validation set. Let us do three way split into train, validation, and test sets. Download the provided csv files containing training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing = pd.read_csv('wk3_kc_house_test_data.csv', dtype=dtype_dict)\n",
    "training = pd.read_csv('wk3_kc_house_train_data.csv', dtype=dtype_dict)\n",
    "validation = pd.read_csv('wk3_kc_house_valid_data.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing['sqft_living_sqrt'] = testing['sqft_living'].apply(sqrt)\n",
    "testing['sqft_lot_sqrt'] = testing['sqft_lot'].apply(sqrt)\n",
    "testing['bedrooms_square'] = testing['bedrooms']*testing['bedrooms']\n",
    "testing['floors_square'] = testing['floors']*testing['floors']\n",
    "\n",
    "training['sqft_living_sqrt'] = training['sqft_living'].apply(sqrt)\n",
    "training['sqft_lot_sqrt'] = training['sqft_lot'].apply(sqrt)\n",
    "training['bedrooms_square'] = training['bedrooms']*training['bedrooms']\n",
    "training['floors_square'] = training['floors']*training['floors']\n",
    "\n",
    "validation['sqft_living_sqrt'] = validation['sqft_living'].apply(sqrt)\n",
    "validation['sqft_lot_sqrt'] = validation['sqft_lot'].apply(sqrt)\n",
    "validation['bedrooms_square'] = validation['bedrooms']*validation['bedrooms']\n",
    "validation['floors_square'] = validation['floors']*validation['floors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e+01,   3.16227766e+01,   1.00000000e+02,\n",
       "         3.16227766e+02,   1.00000000e+03,   3.16227766e+03,\n",
       "         1.00000000e+04,   3.16227766e+04,   1.00000000e+05,\n",
       "         3.16227766e+05,   1.00000000e+06,   3.16227766e+06,\n",
       "         1.00000000e+07])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_penalty = np.logspace(1, 7, num=13)\n",
    "l1_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn a model on TRAINING data using the specified l1_penalty. Make sure to specify normalize=True in the constructor:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the RSS on VALIDATION for the current model (print or save the RSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz Question: Which was the best value for the l1_penalty, i.e. which value of l1_penalty produced the lowest RSS on VALIDATION data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 3.982133273e+14\n",
      "31.6227766017 3.99041900253e+14\n",
      "100.0 4.29791604073e+14\n",
      "316.227766017 4.63739831045e+14\n",
      "1000.0 6.45898733634e+14\n",
      "3162.27766017 1.22250685943e+15\n",
      "10000.0 1.22250685943e+15\n",
      "31622.7766017 1.22250685943e+15\n",
      "100000.0 1.22250685943e+15\n",
      "316227.766017 1.22250685943e+15\n",
      "1000000.0 1.22250685943e+15\n",
      "3162277.66017 1.22250685943e+15\n",
      "10000000.0 1.22250685943e+15\n"
     ]
    }
   ],
   "source": [
    "for i in l1_penalty:\n",
    "    train_model_all = linear_model.Lasso(i, normalize=True) # set parameters\n",
    "    train_model_all.fit(training[all_features], training['price']) # learn weights\n",
    "    y = pd.Series(train_model_all.coef_, index=all_features)\n",
    "    RSS = np.sum((train_model_all.predict(validation[all_features])-validation['price'])**2)\n",
    "    print i,RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have selected an L1 penalty, compute the RSS on TEST data for the model with the best L1 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train2_model_all = linear_model.Lasso(alpha=10.0, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=10.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=True, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2_model_all.fit(training[all_features], training['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(train2_model_all.coef_) + np.count_nonzero(train2_model_all.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them.\n",
    "\n",
    "You are going to implement a simple, two phase procedure to achieve this goal:\n",
    "\n",
    "Explore a large range of ‘l1_penalty’ values to find a narrow region of ‘l1_penalty’ values where models are likely to have the desired number of non-zero weights.\n",
    "Further explore the narrow region you found to find a good value for ‘l1_penalty’ that achieves the desired sparsity. Here, we will again use a validation set to choose the best value for ‘l1_penalty’."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign 7 to the variable ‘max_nonzeros’."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring large range of l1_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For l1_penalty in np.logspace(1, 4, num=20):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz Question: What values did you find for l1_penalty_min and l1_penalty_max?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_nonzeros = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha = np.logspace(1, 4, num=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_of_nonzeros = []\n",
    "for l1_penalty in alpha:\n",
    "    train_model_2 = linear_model.Lasso(l1_penalty, normalize=True) # set parameters\n",
    "    train_model_2.fit(training[all_features], training['price']) # learn weights\n",
    "    if train_model_2.intercept_ <> 0:\n",
    "        counts = np.count_nonzero(train_model_2.coef_) + np.count_nonzero(train_model_2.intercept_)\n",
    "        counts_of_nonzeros.append((l1_penalty,counts))\n",
    "    elif train_model_2.intercept_==0:\n",
    "        counts = np.count_nonzero(train_model_2.coef_) + 1\n",
    "        counts_of_nonzeros.append((l1_penalty,counts))\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10.0, 15), (14.384498882876629, 15), (20.691380811147901, 15), (29.763514416313178, 15), (42.813323987193932, 13), (61.584821106602639, 12), (88.586679041008225, 11), (127.42749857031335, 10), (183.29807108324357, 7), (263.66508987303581, 6), (379.26901907322497, 6), (545.55947811685144, 6), (784.75997035146065, 5), (1128.8378916846884, 3), (1623.776739188721, 3), (2335.7214690901214, 2), (3359.8182862837812, 1), (4832.9302385717519, 1), (6951.9279617756056, 1), (10000.0, 1)]\n"
     ]
    }
   ],
   "source": [
    "print counts_of_nonzeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_greater = [k for k,v in counts_of_nonzeros if v > 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1_penalty_min = max(list_greater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127.42749857031335"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_penalty_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263.66508987303581"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_less = [m for m,n in counts_of_nonzeros if n < 7]\n",
    "l1_penalty_max = min(list_less)\n",
    "l1_penalty_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring narrower range of l1_penalty\n",
    "\n",
    "We now explore the region of l1_penalty we found: between ‘l1_penalty_min’ and ‘l1_penalty_max’. We look for the L1 penalty in this range that produces exactly the right number of nonzeros and also minimizes RSS on the VALIDATION set.\n",
    "\n",
    "For l1_penalty in np.linspace(l1_penalty_min,l1_penalty_max,20):\n",
    "\n",
    "Fit a regression model with a given l1_penalty on TRAIN data. As before, use \"alpha=l1_penalty\" and \"normalize=True\".\n",
    "Measure the RSS of the learned model on the VALIDATION set\n",
    "Find the model that the lowest RSS on the VALIDATION set and has sparsity equal to ‘max_nonzeros’. (Again, take account of the intercept when counting the number of nonzeros.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts_of_nonzeros_2 = []\n",
    "RSS_list = []\n",
    "for l1_penalty in np.linspace(l1_penalty_min,l1_penalty_max,20):\n",
    "    train_model_3 = linear_model.Lasso(l1_penalty, normalize=True) # set parameters\n",
    "    train_model_3.fit(training[all_features], training['price']) # learn weights\n",
    "    RSS = np.sum((train_model_3.predict(validation[all_features])-validation['price'])**2)\n",
    "    RSS_list.append((l1_penalty,RSS))\n",
    "    if train_model_3.intercept_ <> 0:\n",
    "        counts = np.count_nonzero(train_model_3.coef_) + np.count_nonzero(train_model_3.intercept_)\n",
    "        counts_of_nonzeros_2.append((l1_penalty,counts))\n",
    "    elif train_model_3.intercept_==0:\n",
    "        counts = np.count_nonzero(train_model_3.coef_) + 1\n",
    "        counts_of_nonzeros_2.append((l1_penalty,counts))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[156.10909673930755,\n",
       " 163.27949628155611,\n",
       " 170.44989582380464,\n",
       " 177.6202953660532,\n",
       " 184.79069490830176,\n",
       " 191.96109445055032,\n",
       " 199.13149399279888]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_7_list = [j for j,p in counts_of_nonzeros_2 if p == 7] \n",
    "max_7_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RSS_list_2 = [(y,x) for x,y in RSS_list if x in max_7_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RSS_list_2.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(440037365263316.94, 156.10909673930755),\n",
       " (440777489641605.56, 163.27949628155611),\n",
       " (441566698090138.94, 170.44989582380464),\n",
       " (442406413188665.06, 177.6202953660532),\n",
       " (443296716874313.06, 184.79069490830176),\n",
       " (444239780526141.2, 191.96109445055032),\n",
       " (445230739842613.8, 199.13149399279888)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RSS_list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=156.10909673930755, copy_X=True, fit_intercept=True,\n",
       "   max_iter=1000, normalize=True, positive=False, precompute=False,\n",
       "   random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model_4 = linear_model.Lasso(max_7_list[0], normalize=True) # set parameters\n",
    "train_model_4.fit(training[all_features], training['price']) # learn weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bedrooms                -0.000000\n",
       "bedrooms_square         -0.000000\n",
       "bathrooms            10610.890284\n",
       "sqft_living            163.380252\n",
       "sqft_living_sqrt         0.000000\n",
       "sqft_lot                -0.000000\n",
       "sqft_lot_sqrt           -0.000000\n",
       "floors                   0.000000\n",
       "floors_square            0.000000\n",
       "waterfront          506451.687115\n",
       "view                 41960.043555\n",
       "condition                0.000000\n",
       "grade               116253.553700\n",
       "sqft_above               0.000000\n",
       "sqft_basement            0.000000\n",
       "yr_built             -2612.234880\n",
       "yr_renovated             0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(train_model_4.coef_, index = all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
